{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Tree-based Method for Anomaly Detection\n",
    "\n",
    "Goal of this workbook\n",
    "\n",
    "1. Know when to apply\n",
    "2. What's the difference with a usual random forest\n",
    "3. Know how to apply\n",
    "4. Try a few detection methods with various data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataframe / analysis tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from scipy.stats import multivariate_normal, uniform\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Helpful functions\n",
    "def normalize(x):\n",
    "    mu = np.mean(x,axis=0)\n",
    "    sigma = np.std(x,axis=0)\n",
    "    return (x - mu)/sigma\n",
    "\n",
    "def ad_plot(x, y, mask):\n",
    "    plt.figure(figsize=(16,8))\n",
    "    sns.kdeplot(x, y)\n",
    "    sns.regplot(x=x[~mask], y=y[~mask], fit_reg=False,color='g',scatter_kws={'alpha':0.25})\n",
    "    sns.regplot(x=x[mask], y=y[mask],fit_reg=False,color='red')\n",
    "    \n",
    "def estimate_gaussian(x):\n",
    "    # Step 1: Normalize\n",
    "    x = normalize(x)\n",
    "    # Step 2: Use sp.stats.norm.pdf on results above\n",
    "    x = x.apply(lambda v: sp.stats.norm.pdf(v),1)\n",
    "    # Step 3: get Probabilities of Feature_1 x Features_2 x .... Feature_n\n",
    "    return x.apply(np.prod,1)\n",
    "\n",
    "def get_mu_sig(x):\n",
    "    mu = np.mean(x, axis=0)\n",
    "    sigma = np.cov(x.T)\n",
    "    return mu, sigma\n",
    "\n",
    "def multivariateGaussian(x,mu,sigma):\n",
    "    p = multivariate_normal(mean=mu, cov=sigma)\n",
    "    return p.pdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "[Lymph]('https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29')\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link] \n",
    "\n",
    "\n",
    "[MUSK]('https://archive.ics.uci.edu/ml/datasets/Musk+%28Version+2%29')\n",
    "\n",
    "This dataset describes a set of 102 molecules of which 39 are judged by human experts to be musks and the remaining 63 molecules are judged to be non-musks. The goal is to learn to predict whether new molecules will be musks or non-musks. However, the 166 features that describe these molecules depend upon the exact shape, or conformation, of the molecule. Because bonds can rotate, a single molecule can adopt many different shapes. To generate this data set, all the low-energy conformations of the molecules were generated to produce 6,598 conformations. Then, a feature vector was extracted that describes each conformation. \n",
    "\n",
    "\n",
    "[Women's Breast Cancer]('http://odds.cs.stonybrook.edu/lympho/')\n",
    "\n",
    "*missing info*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_musk = loadmat('./data/musk.mat')\n",
    "df_wbc = loadmat('./data/wbc.mat')\n",
    "df_lymph = loadmat('./data/lympho.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn:\n",
    "Using methods from before, apply these methods to the data. Look at the shape of distributions and correct to normal if needed. Use scatter or density plots to explore your data. \n",
    "\n",
    "\n",
    "Guiding Questions\n",
    "1. Do these models work well? \n",
    "2. If no, why not?\n",
    "3. Try working with an isolation forest model. Does it work well? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_in = df_musk\n",
    "X = normalize(dat_in['X'])\n",
    "y = dat_in['y']\n",
    "\n",
    "mu, sig = get_mu_sig(X)\n",
    "pred = multivariateGaussian(X, mu, sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2924   41]\n",
      " [   0   97]]\n",
      "  \n",
      "  \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      0.99      2965\n",
      "        1.0       0.70      1.00      0.83        97\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = 1/100000000000\n",
    "y_pred = (pred < threshold) + 0.0\n",
    "y_true = y.flatten()\n",
    "\n",
    "\n",
    "print(confusion_matrix\n",
    "      (y_pred= y_pred, y_true= y_true))\n",
    "print('  ')\n",
    "print('  ')\n",
    "print(classification_report(y_pred= y_pred, y_true= y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation Forest:\n",
    "- Tree based method: Like Random forest, takes subsets of data. This means it's great for high-dimensional data.\n",
    "- Not cluster or density based\n",
    "- Works by randomly partitioning data set. \n",
    "- The more partitions, the more \"normal\" the data point is. The fewer, the more anomalous it is. \n",
    "- Get an \"anomaly score\". Essentially, the average of each point's numbers of splits to reach averaged across all trees and and ordered. \n",
    "- Whereas in Gaussian and Multivariate Gaussian, we can build relatively simple decision boundaries, with iForest you can build more complex ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Trees Make up an Isolation Forest\n",
    "![title](http://pubs.rsc.org/services/images/RSCpubs.ePlatform.Service.FreeContent.ImageService.svc/ImageService/Articleimage/2016/AY/c6ay01574c/c6ay01574c-f1_hi-res.gif)\n",
    "\n",
    "\n",
    "### In an iTree, how many nodes does it take to isolate?\n",
    "\n",
    "![title](https://image.slidesharecdn.com/gerster-anomalyv4-150730232953-lva1-app6892/95/anomaly-detection-using-isolation-forests-10-638.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2908   57]\n",
      " [   0   97]]\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2908\n",
      "          1       1.00      0.63      0.77       154\n",
      "\n",
      "avg / total       0.98      0.98      0.98      3062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dat_if = df_musk\n",
    "X = dat_if['X']\n",
    "y = dat_if['y']\n",
    "from sklearn.ensemble import IsolationForest\n",
    "clf = IsolationForest(n_estimators=500, n_jobs= -1, contamination=.05)\n",
    "clf.fit(X,y)\n",
    "y_pred = (clf.predict(X) == -1) +0\n",
    "y_true = y.flatten()\n",
    "\n",
    "print(confusion_matrix(y_pred=y_pred, y_true = y_true))\n",
    "print('')\n",
    "print(classification_report(y_pred, y_true))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
