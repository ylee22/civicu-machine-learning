{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing IMDB Data in Keras using RNNs\n",
    "\n",
    "Let's use Recurrent Neural Networks, and in particular LSTMs, to perform sentiment analysis in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
      "Using Theano backend.\n"
=======
      "Using TensorFlow backend.\n"
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data\n",
    "\n",
    "This dataset comes preloaded with Keras, so one simple command will get us training and testing data. There is a parameter for how many words we want to look at (vocabulary size). Let's set it at to 5000, but feel free to experiment."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "execution_count": 2,
=======
   "execution_count": 16,
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb  # import the built-in imdb dataset in Keras\n",
    "\n",
    "# Set the vocabulary size\n",
    "vocabulary_size = 5000\n",
    "\n",
    "# Load in training and test data (note the difference in convention compared to scikit-learn)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
    "print(\"Loaded dataset with {} training samples, {} test samples\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examining the data\n",
    "Notice that the data has been already pre-processed, where all the words have numbers, and the reviews come in as a vector with the words that the review contains. For example, if the word 'the' is the first one in our dictionary, and a review contains the word 'the', then there is a 1 in the corresponding vector.\n",
    "\n",
    "The output comes as a vector of 1's and 0's, where 1 is a positive sentiment for the review, and 0 is negative."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "execution_count": 3,
=======
   "execution_count": 17,
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Review ---\n",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
      "[1, 13, 244, 6, 194, 337, 6, 2, 787, 1716, 5, 207, 110, 98, 32, 5, 14, 9, 31, 7, 4, 118, 45, 163, 731, 5, 6, 356, 13, 386, 14, 18, 32, 2088, 45, 87, 18, 117, 362, 88, 45, 73, 2379, 5, 87, 18, 1473, 5, 1629, 88, 45, 163, 5, 24, 120, 4, 350, 13, 296, 12, 54, 13, 16, 117, 5, 13, 131, 106, 12, 150, 12, 47, 87, 411, 15, 61, 223, 5, 13, 3194, 32, 4, 58, 4, 116, 9, 87, 5, 12, 115, 214, 154, 48, 25, 40, 2447, 2953, 5, 2, 25, 80, 119, 14, 207, 296, 111, 6, 2379, 20, 11, 61, 58, 5, 14, 9, 4, 118, 7, 98, 32, 806, 910, 13, 545, 386, 14, 20, 5, 32, 4, 2, 787, 1716, 287, 36, 32, 1271, 8, 32, 2088, 5, 26, 32, 955, 5, 55, 441]\n",
      "--- Label ---\n",
      "1\n"
=======
      "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
      "--- Label ---\n",
      "0\n"
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
     ]
    }
   ],
   "source": [
    "# Print a sample review and its label\n",
    "idx = 2\n",
    "print(\"--- Review ---\")\n",
    "print(X_train[idx])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the label is an integer (0 for negative, 1 for positive), and the review itself is stored as a sequence of integers. These are word IDs that have been preassigned to individual words. To map them back to the original words, you can use the dictionary returned by imdb.get_word_index()."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "execution_count": 4,
=======
   "execution_count": 13,
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 6s 4us/step\n",
      "--- Review (with words) ---\n",
      "['the', 'was', 'rather', 'is', 'thought', 'completely', 'is', 'and', '9', 'pop', 'to', 'always', 'life', 'any', 'an', 'to', 'as', 'it', 'by', 'br', 'of', 'where', 'if', 'makes', 'falls', 'to', 'is', 'need', 'was', 'wonderful', 'as', 'but', 'an', 'logic', 'if', 'him', 'but', 'over', 'production', 'most', 'if', 'much', 'danger', 'to', 'him', 'but', 'fresh', 'to', 'listen', 'most', 'if', 'makes', 'to', 'his', 'show', 'of', 'try', 'was', 'plays', 'that', 'no', 'was', 'with', 'over', 'to', 'was', 'these', 'character', 'that', 'years', 'that', 'there', 'him', 'dialogue', 'for', 'only', 'whole', 'to', 'was', 'sons', 'an', 'of', 'my', 'of', 'love', 'it', 'him', 'to', 'that', 'best', 'role', 'work', 'what', 'have', 'just', 'texas', 'interpretation', 'to', 'and', 'have', 'into', 'did', 'as', 'always', 'plays', 'plot', 'is', 'danger', 'on', 'this', 'only', 'my', 'to', 'as', 'it', 'of', 'where', 'br', 'any', 'an', 'fall', 'badly', 'was', 'fight', 'wonderful', 'as', 'on', 'to', 'an', 'of', 'and', '9', 'pop', 'worth', 'from', 'an', 'attack', 'in', 'an', 'logic', 'to', 'he', 'an', 'plenty', 'to', 'time', 'overall']\n",
      "--- Label ---\n",
      "1\n"
=======
      "--- Review (with words) ---\n",
      "--- Label ---\n",
      "0\n"
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
     ]
    }
   ],
   "source": [
    "# Map word IDs back to words\n",
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "print(\"--- Review (with words) ---\")\n",
    "' '.join(id2word[i] for i in X_train[0])\n",
    "print(\"--- Label ---\")\n",
    "print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate it so heart shows to years of every never going villaronga help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of gilmore's br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id = imdb.get_word_index()\n",
    "id2word = {i: word for word, i in word2id.items()}\n",
    "' '.join(id2word[i] for i in X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the data\n",
    "\n",
    "In order to feed this data into your RNN, all input documents must have the same length. Let's limit the maximum review length to `max_words` by truncating longer reviews and padding shorter reviews with a null value (0). You can accomplish this easily using the `pad_sequences()` function in Keras. For now, set `max_words` to 500."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-46f8f6ff74be>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-46f8f6ff74be>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    X_train = ?\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
   "source": [
    "from keras.preprocessing import sequence\n",
    "\n",
    "# Set the maximum number of words per document (for both training and testing)\n",
    "max_words = 500\n",
    "\n",
    "# TODO: Pad sequences in X_train and X_test\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Design an RNN model for sentiment analysis\n",
    "\n",
    "Build your model architecture in the code cell below. We have imported some layers from Keras that you might need but feel free to use any other layers / transformations you like.\n",
    "Remember that your input is a sequence of words (technically, integer word IDs) of maximum length = max_words, and your output is a binary sentiment label (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ed22890555ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO: Design your model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/civicu/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# TODO: Design your model\n",
    "model = Sequential()\n",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
    "model.add\n",
=======
    "model.add(Embedding(1000, 300, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the model\n",
    "Run the model here. Experiment with different batch_size, and number of epochs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile your model, specifying a loss function, optimizer, and metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once compiled, you can kick off the training process. There are two important training parameters that you have to specify - batch size and number of training epochs, which together with your model architecture determine the total training time.\n",
    "Training may take a while, so grab a cup of coffee, or better, go for a hike! If possible, consider using a GPU, as a single training run can take several hours on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Specify training parameters: batch size and number of epochs\n",
    "\n",
    "# TODO(optional): Reserve/specify some training data for validation (not to be used for training)\n",
    "\n",
    "# TODO: Train your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the model\n",
    "\n",
    "Once you have trained your model, it's time to see how well it performs on unseen test data.\n",
    "This will give you the accuracy of the model. Can you get something over 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your model on the test set\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)  # returns loss and other metrics specified in model.compile()\n",
    "print(\"Test accuracy:\", scores[1])  # scores[1] should correspond to accuracy if you passed in metrics=['accuracy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD:lessons/11-NNs-and-RNNs/sentiment_analysis/IMDB_Keras_RNN.ipynb
   "version": "3.6.1"
=======
   "version": "3.6.3"
>>>>>>> aa717877ef16c7773c5e0be523b125021d6308da:lessons/11-NNs-and-RNNs/IMDB_Keras_RNN.ipynb
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
